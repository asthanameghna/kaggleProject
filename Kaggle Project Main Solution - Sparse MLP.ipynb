{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Marcus/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Neural Network\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record total notebook run time\n",
    "notebook_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data from TSV files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Marcus/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Took 8.37s\n"
     ]
    }
   ],
   "source": [
    "print('Parsing data from TSV files...')\n",
    "start_time = time.time()\n",
    "train_df = pd.read_csv('train.tsv', delimiter='\\t', index_col=['train_id'])\n",
    "X_test_df = pd.read_csv('test.tsv', delimiter='\\t', index_col=['test_id'])\n",
    "print(f'Done. Took {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "For data exploration, refer to the file \"Data Exploration.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 874 zero-price entries (train)\n"
     ]
    }
   ],
   "source": [
    "# Drop training entries where price is zero\n",
    "initial_size = train_df.shape[0]\n",
    "train_df = train_df.drop(train_df[(train_df['price'] == 0)].index)\n",
    "print(f'Dropped {initial_size - train_df.shape[0]} zero-price entries (train)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X/y split: split the training df into X (features/inputs) and y (target variable, price)\n",
    "y_train_df = train_df.loc[:, 'price']\n",
    "y_train_df = pd.to_numeric(y_train_df)\n",
    "\n",
    "X_train_df = train_df\n",
    "del X_train_df['price']\n",
    "\n",
    "#X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2                       AVA-VIV Blouse                  1   \n",
       "3                Leather Horse Statues                  1   \n",
       "4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  shipping  \\\n",
       "0                                  Men/Tops/T-shirts        NaN         1   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer         0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target         1   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN         1   \n",
       "4                            Women/Jewelry/Necklaces        NaN         0   \n",
       "\n",
       "                                    item_description  \n",
       "0                                 No description yet  \n",
       "1  This keyboard is in great condition and works ...  \n",
       "2  Adorable top with a hint of lace and a key hol...  \n",
       "3  New with tags. Leather horses. Retail for [rm]...  \n",
       "4          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate training and test data\n",
    "X_df = pd.concat([X_train_df, X_test_df], axis=0)\n",
    "\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with ''\n",
    "X_df['brand_name'] = X_df['brand_name'].fillna('unknown')\n",
    "\n",
    "# Replace NaN and 'No description yet' with ''\n",
    "X_df['item_description'] = X_df['item_description'].apply(lambda x: '' if x=='No description yet' or type(x) != str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovering brands...\n",
      "Done. Time taken: 257.68s\n",
      "Recovered 133056 brands out of 927861 missing brands\n"
     ]
    }
   ],
   "source": [
    "# Recover missing brands, by trying to guess unknown brands from their name and category\n",
    "start_time = time.time()\n",
    "\n",
    "def category_set(categories):\n",
    "    return set(categories)\n",
    "\n",
    "def recover_brands(name, category):    \n",
    "    for brand in brands_descending:\n",
    "        if brand in name and category in brand_categories[brand]:\n",
    "            return brand\n",
    "    return 'unknown'\n",
    "\n",
    "# Find the category combinations that each brand is present in\n",
    "brand_categories = dict(X_df[X_df['brand_name'] != 'unknown'][['brand_name', 'category_name']].astype(str).\\\n",
    "                       groupby('brand_name').agg(category_set).reset_index().values.tolist())\n",
    "\n",
    "# Brands sorted by decreasing length (longer brand names will have priority when recovering)\n",
    "brands_descending = list(sorted(filter(lambda y: len(y) >= 3, list(brand_categories.keys())),\\\n",
    "                                key = lambda x: -len(x)))\n",
    "\n",
    "print('Recovering brands...')\n",
    "# Get entries that have an unknown brand, retrieve just the 'name' and 'category_name'\n",
    "# columns, then convert to np array\n",
    "X_unknown_brand = X_df[X_df['brand_name'] == 'unknown']\n",
    "X_unknown_brand = np.array(X_unknown_brand[['name','category_name']]) # .astype('str')\n",
    "\n",
    "# Recover brands and update our dataframe\n",
    "recovered_brands = [recover_brands(name, category) for name, category in X_unknown_brand]\n",
    "X_df.loc[X_df['brand_name'] == 'unknown', 'brand_name'] = recovered_brands\n",
    "\n",
    "# Get the number of brands recovered\n",
    "num_recovered = len(X_unknown_brand) - len(X_df[X_df['brand_name'] == 'unknown'])\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s')\n",
    "print(f'Recovered {num_recovered} brands out of {len(X_unknown_brand)} missing brands')\n",
    "\n",
    "#X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting categories into subcategories...\n",
      "Done. Time taken: 6.45s\n"
     ]
    }
   ],
   "source": [
    "def split_categories(category_name):\n",
    "    \"\"\"This function will split the category into multiple separate subcategories \"\"\"\n",
    "    # \"try\" since some category_names are NaN. If we get more than 3 categories, only the\n",
    "    # first 3 will be returned\n",
    "    try:\n",
    "        categories = category_name.split('/')\n",
    "        return categories[:3]\n",
    "    except:\n",
    "        return '', '', ''\n",
    "    \n",
    "start_time = time.time()\n",
    "print('Splitting categories into subcategories...')\n",
    "# Creates three new columns, one for each \"level\" of the category\n",
    "X_df['category1'], X_df['category2'], X_df['category3']=\\\n",
    "zip(*X_df['category_name'].apply(split_categories))\n",
    "\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s')\n",
    "\n",
    "#X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables and storing as sparse matrices...\n",
      "Done. Time taken: 292.44s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('Creating dummy variables and storing as sparse matrices...')\n",
    "X_brand = csr_matrix(pd.get_dummies(X_df['brand_name'], sparse=True, prefix='brand'))\n",
    "X_cat1 = csr_matrix(pd.get_dummies(X_df['category1'], sparse=True, prefix='cat1'))\n",
    "X_cat2 = csr_matrix(pd.get_dummies(X_df['category2'], sparse=True, prefix='cat2'))\n",
    "X_cat3 = csr_matrix(pd.get_dummies(X_df['category3'], sparse=True, prefix='cat3'))\n",
    "X_cond = csr_matrix(pd.get_dummies(X_df['item_condition_id'], sparse=True, prefix='cond'))\n",
    "X_ship = csr_matrix(pd.get_dummies(X_df['shipping'], sparse=True, prefix='ship'))\n",
    "\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform name and item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorising name...\n",
      "Done. Time taken: 12.04s\n",
      "\n",
      "Vectorising item description...\n",
      "Done. Time taken: 132.08s\n"
     ]
    }
   ],
   "source": [
    "cv_name = CountVectorizer(max_features=20000, lowercase=True, token_pattern='\\w+', ngram_range=(1,1))\n",
    "tv_desc = TfidfVectorizer(max_features=20000, lowercase=True, token_pattern='\\w+', ngram_range=(1,2))\n",
    "\n",
    "# Vectorise name\n",
    "start_time = time.time()\n",
    "print('Vectorising name...')\n",
    "X_name = cv_name.fit_transform(X_df['name'])\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s\\n')\n",
    "\n",
    "# Vectorise item description\n",
    "start_time = time.time()\n",
    "print('Vectorising item description...')\n",
    "X_desc = tv_desc.fit_transform(X_df['item_description'])\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features and prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimensions:\n",
      "(2175020, 20000)\n",
      "(2175020, 5)\n",
      "(2175020, 2)\n",
      "(2175020, 20000)\n",
      "(2175020, 5288)\n",
      "(2175020, 11)\n",
      "(2175020, 114)\n",
      "(2175020, 883)\n"
     ]
    }
   ],
   "source": [
    "print('Feature dimensions:')\n",
    "for feature in (X_name,\n",
    "                X_cond,\n",
    "                X_ship,\n",
    "                X_desc,\n",
    "                X_brand,\n",
    "                X_cat1,\n",
    "                X_cat2,\n",
    "                X_cat3):\n",
    "    print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating overall input data...\n",
      "Done. Time taken: 8.40s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Creating overall input data...')\n",
    "\n",
    "# Create final sparse matrix for X\n",
    "X_csr = hstack((X_name,\n",
    "                X_cond,\n",
    "                X_ship,\n",
    "                X_desc,\n",
    "                X_brand,\n",
    "                X_cat1,\n",
    "                X_cat2,\n",
    "                X_cat3)\n",
    "                ).tocsr()\n",
    "\n",
    "split = len(X_train_df)\n",
    "X_input = X_csr[:split]\n",
    "X_test = X_csr[split:]\n",
    "\n",
    "# Convert y to np array, then log(y+1)\n",
    "y_input = np.array(y_train_df).reshape(-1,1)\n",
    "y_input = np.log1p(y_input)\n",
    "\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481661, 46303)\n",
      "(1481661, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of our model inputs\n",
    "print(X_input.shape)\n",
    "print(y_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation split...\n",
      "Done. Time taken: 2.52s\n",
      "\n",
      "Train shapes\n",
      "X: (1333494, 46303)\n",
      "Y: (1333494, 1)\n",
      "\n",
      "Validation shapes\n",
      "X: (148167, 46303)\n",
      "Y: (148167, 1)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('Creating train/validation split...')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_input, y_input, test_size=0.1)\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s\\n')\n",
    "\n",
    "print(f'Train shapes\\nX: {X_train.shape}\\nY: {y_train.shape}\\n')\n",
    "print(f'Validation shapes\\nX: {X_val.shape}\\nY: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keras functions\n",
    "def r2_metric(y, y_hat):\n",
    "    RSS = K.sum(K.square(y - y_hat))\n",
    "    TSS = K.sum(K.square(y - K.mean(y)))\n",
    "    r2 = 1 - RSS / (TSS + K.epsilon())\n",
    "    return r2\n",
    "\n",
    "def RMSLE_metric(y, y_hat):    \n",
    "    RMSLE = K.sqrt(K.mean(K.square(y_hat - y)))\n",
    "    return RMSLE\n",
    "\n",
    "## Numpy functions\n",
    "def calc_r2(y, y_hat):\n",
    "    RSS = np.sum((y - y_hat)**2)\n",
    "    TSS = np.sum((y - np.mean(y))**2)\n",
    "    r2 = 1 - RSS / TSS\n",
    "    return r2\n",
    "\n",
    "def calc_RMSLE(y, y_hat):\n",
    "    RMSLE = np.sqrt(np.mean((np.log(y_hat + 1) - np.log(y + 1))**2))\n",
    "    return RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 46303)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 192)               8890368   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,906,945\n",
      "Trainable params: 8,906,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(X_input.shape[1],), dtype='float32', sparse=True)\n",
    "\n",
    "hidden1 = Dropout(0.3)(Dense(192, activation='relu')(model_input))\n",
    "hidden2 = Dropout(0.3)(Dense(64, activation='relu')(hidden1))\n",
    "hidden3 = Dropout(0.3)(Dense(64, activation='relu')(hidden2))\n",
    "model_output = Dense(1)(hidden3)\n",
    "\n",
    "model = keras.Model(model_input, model_output)\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.adam(lr=3e-3), metrics=[RMSLE_metric])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1333494 samples, validate on 148167 samples\n",
      "Epoch 1/10\n",
      "1333494/1333494 [==============================] - 78s 58us/step - loss: 0.4980 - RMSLE_metric: 0.6654 - val_loss: 0.2017 - val_RMSLE_metric: 0.4490\n",
      "Epoch 2/10\n",
      "1333494/1333494 [==============================] - 77s 58us/step - loss: 0.2778 - RMSLE_metric: 0.5268 - val_loss: 0.1911 - val_RMSLE_metric: 0.4371\n",
      "Epoch 3/10\n",
      "1333494/1333494 [==============================] - 77s 58us/step - loss: 0.2329 - RMSLE_metric: 0.4824 - val_loss: 0.1848 - val_RMSLE_metric: 0.4297\n",
      "Epoch 4/10\n",
      "1333494/1333494 [==============================] - 78s 58us/step - loss: 0.1956 - RMSLE_metric: 0.4422 - val_loss: 0.1785 - val_RMSLE_metric: 0.4224\n",
      "Epoch 5/10\n",
      "1333494/1333494 [==============================] - 75s 56us/step - loss: 0.1644 - RMSLE_metric: 0.4054 - val_loss: 0.1774 - val_RMSLE_metric: 0.4210\n",
      "Epoch 6/10\n",
      "1333494/1333494 [==============================] - 77s 58us/step - loss: 0.1417 - RMSLE_metric: 0.3764 - val_loss: 0.1789 - val_RMSLE_metric: 0.4229\n",
      "Training finished. Time taken: 462.79s\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "# brand recovery - 0.4196\n",
    "history = model.fit(X_train, y_train, batch_size=2048, epochs=10, validation_data=(X_val, y_val), verbose=1,\n",
    "                    callbacks=[EarlyStopping(patience=1, monitor='val_loss', restore_best_weights=True)])\n",
    "\n",
    "print(f'Training finished. Time taken: {time.time() - training_start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333494/1333494 [==============================] - 50s 37us/step\n",
      "148167/148167 [==============================] - 6s 37us/step\n"
     ]
    }
   ],
   "source": [
    "# Get train/validation predictions\n",
    "y_hat_train = model.predict(X_train, verbose=1)\n",
    "y_hat_val = model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE\n",
      "Train: 0.3233\n",
      "Val: 0.4211\n",
      "\n",
      "r2\n",
      "Train: 0.6774\n",
      "Val: 0.5426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Root mean squared logarithmic error\n",
    "RMSLE_train = calc_RMSLE(np.expm1(y_train), np.expm1(y_hat_train))\n",
    "RMSLE_val = calc_RMSLE(np.expm1(y_val), np.expm1(y_hat_val))\n",
    "print(f'RMSLE\\nTrain: {RMSLE_train:.4f}\\nVal: {RMSLE_val:.4f}\\n')\n",
    "\n",
    "# R squared (fraction of variance explained)\n",
    "r2_train = calc_r2(np.expm1(y_train), np.expm1(y_hat_train))\n",
    "r2_val = calc_r2(np.expm1(y_val), np.expm1(y_hat_val))\n",
    "print(f'r2\\nTrain: {r2_train:.4f}\\nVal: {r2_val:.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693359/693359 [==============================] - 26s 37us/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_hat_test = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission file...\n",
      "Done. Time taken: 1.84s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Creating submission file...')\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame()\n",
    "submission['test_id'] = range(len(y_hat_test))\n",
    "submission['price'] = np.expm1(y_hat_test)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f'Done. Time taken: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notebook run time: 1268.27s\n"
     ]
    }
   ],
   "source": [
    "print(f'Total notebook run time: {time.time() - notebook_start:.2f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
